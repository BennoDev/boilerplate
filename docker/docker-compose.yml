# https://medium.com/@blackhorseya/deploying-opentelemetry-collector-jaeger-and-prometheus-with-docker-compose-for-observability-fedd7c0898b5
# https://www.npmjs.com/package/@opentelemetry/auto-instrumentations-node
# https://github.com/open-telemetry/opentelemetry-collector/blob/main/receiver/README.md
# https://opentelemetry.io/docs/collector/configuration/
# https://hub.docker.com/r/grafana/grafana
# https://hub.docker.com/r/prom/prometheus
# https://grafana.com/docs/loki/latest/setup/install/docker/

# OTEL INSTRUMENTATION:
# Instrumentation needs to happen at the earliest possible point. Ideally before any framework / libraries are initialized.
# This is why we have a separate init.ts file for each service currently, but ideally you can export an /init file from a library or something and import that.
# If not instrumenting early, half of the instrumentations will not work at all.
#
# BULLMQ:
# Adding OTEL support to BullMQ is not difficult; you need to use the bullmq-otel package & BullMQOtel class.
# For NestJS, we are once again dealing with confusing BullMQ setup, as we have:
#  - forRoot(Async)
#  - registerQueue(Async)
#  - @Processor
# The place where you add this is important.
# For the PRODUCER, you CAN add it at the forRoot level - and MAYBE at the registerQueue level if you want to have multiple queues with different span names - which makes sense!
# For the CONSUMER, you MUST add it at the @Processor level. Any other place seems to have no effect whatsoever!
#
# DISTRIBUTED TRACING:
# For distributed tracing, you NEED to have propagation through a textMapPropagator!
# What the purpose of the SpanProcessor is - not entirely clear. Both with and without processor it works quite well :)
# Tracing with custom decorators, or via the { trace } import from @opentelemetry/api is straightforward and powerful.
#
# LOGGING: https://grafana.com/docs/loki/latest/send-data/otel/
# OTEL tracing makes own tracing solution redundant.
# HTTP OTEL exporter seems to be the best solution for logging, not sure why.
#
# TODO:
# - Try Grafana Tempo
# - Figure out Prometheus for NodeJS

services:
    postgres:
        # Replace :latest with desired version when starting a new project
        image: postgres:latest
        ports:
            - 5432:5432
        env_file:
            - ./.env.postgres
    redis:
        # Replace :latest with desired version when starting a new project
        image: redis:latest
        ports:
            - 6379:6379

    otel-collector:
        image: otel/opentelemetry-collector:latest
        command: ['--config=/etc/otel-collector-config.yml']
        volumes:
            - ./config/otel-collector-config.yml:/etc/otel-collector-config.yml
        ports:
            - 4317:4317 # OTLP gRPC receiver

    # Check UI at http://localhost:9090
    prometheus:
        image: prom/prometheus:latest
        volumes:
            - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
        ports:
            - '9090:9090'

    # Check UI at http://localhost:16686
    jaeger:
        image: jaegertracing/all-in-one:latest
        ports:
            - 6831:6831/udp # UDP port for Jaeger agent
            - 16686:16686 # Web UI
            - 14268:14268 # HTTP port for spans

    loki:
        image: grafana/loki:latest
        ports:
            - 3100:3100
            - 9096:9096
        volumes:
            - ./config/loki-config.yml:/etc/loki/loki-config.yaml

    # Check UI at http://localhost:3000
    grafana:
        image: grafana/grafana:latest
        ports:
            - 3000:3000
        environment:
            - GF_SECURITY_ADMIN_PASSWORD=admin
        volumes:
            - ./volumes/grafana-storage:/var/lib/grafana
            - ./config/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml
